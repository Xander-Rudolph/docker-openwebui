services:
  stable-diffusion-webui-nvid:
    profiles:
      - NVIDIA
    # If you want to run a build instead of pulling the image
    # build: ./stable-diffusion
    image: ghcr.io/xander-rudolph/stable-diffusion:latest
    container_name: stable-diffusion-webui
    ports:
      - "${SD_WEBUI_PORT}:7860"
    environment:
      - COMMANDLINE_ARGS=--medvram --xformers --enable-insecure-extension-access
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
    volumes:
      - sd_models:/models
      - sd_config:/config
      - sd_outputs:/outputs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  
  ollama-nvid:
    profiles:
      - NVIDIA
    image: ollama/ollama
    container_name: ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "${OLLAMA_PORT}:11434"
    restart: always
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ollama-rocm:
    profiles:
      - AMD
    image: ollama/ollama:rocm
    container_name: ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "${OLLAMA_PORT}:11434"
    restart: always    
    devices:
      - /dev/kfd
      - /dev/dri

  open-webui:
    profiles:
      - AMD
      - NVIDIA
      - default
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "${OPEN_WEBUI_PORT}:8080"
    environment:
      - AUTOMATIC1111_BASE_URL=http://stable-diffusion-webui:${SD_WEBUI_PORT}/
      - ENABLE_IMAGE_GENERATION=True
      - OLLAMA_BASE_URL=http://${OLLAMA_HOST:-ollama}:${OLLAMA_PORT}
      - ENABLE_RAG_WEB_SEARCH=${ENABLE_RAG_WEB_SEARCH:-True}
      - RAG_WEB_SEARCH_ENGINE=${RAG_WEB_SEARCH_ENGINE:-searxng}
      - RAG_WEB_SEARCH_RESULT_COUNT=${RAG_WEB_SEARCH_RESULT_COUNT:-3}
      - RAG_WEB_SEARCH_CONCURRENT_REQUESTS=${RAG_WEB_SEARCH_CONCURRENT_REQUESTS:-30}
      - SEARXNG_QUERY_URL=http://${SEARXNG_HOSTNAME:-searxng}:${SEARXNG_PORT:-8080}/search?q=<query>
    volumes:
      - owui_data:/app/backend/data
    restart: always

  searxng:
    profiles:
      - AMD
      - NVIDIA
      - default
    container_name: searxng
    image: searxng/searxng:latest
    ports:
      - "${SEARXNG_PORT:-8080}:8080"  
    volumes:
      - search:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
      - UWSGI_WORKERS=${SEARXNG_UWSGI_WORKERS:-4}
      - UWSGI_THREADS=${SEARXNG_UWSGI_THREADS:-4}
      - TRUSTED_NETWORKS="10.0.0.0/8,192.168.0.0/16" # allow calls from most A and C networks
      - SEARXNG_API__REQUIRE_API_KEY=False # disable API key requirement
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"
    depends_on:
      - open-webui

volumes:
  sd_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${SD_MODELS_DIR}"
  sd_config:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${SD_CONFIG_DIR}"
  sd_outputs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${SD_OUTPUTS_DIR}"
  tts_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${TTS_MODELS}"
  stt_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${STT_MODELS}"
  search:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${SEARCH_DIR}"
  sd_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${SD_DATA_DIR}"
  ollama_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${LAMA_DATA_DIR}"
  owui_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: "${OWUI_DATA_DIR}"
